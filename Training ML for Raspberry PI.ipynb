{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Machine Learning Model for Raspberry PI\n",
    "This notebook demonstrates how to prepare Gaussian Mixture Model and Isotronic Regression for Audio Anomaly Detection in Raspberry PI. Training is done based on samples recorded with Raspberry PI. Trained model is saved for export to Raspberry PI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.fftpack\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing\n",
    "from scipy.signal import welch\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import librosa\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 32000 #sampling rate of audio\n",
    "SEGMENT_TIME = 2 # in seconds, duration of each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from input signal(in our case Audio). \n",
    "# Various features are extracted using Librosa and concatenated as a 1D Array\n",
    "def extract_feature(X):\n",
    "    sample_rate = SAMPLE_RATE\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return np.hstack([mfccs,chroma,mel,contrast,tonnetz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read file, split into segments and retrieve features for each segment\n",
    "def read_process_file(filename):\n",
    "    print(\"Processing file: \", filename)\n",
    "    \n",
    "    # Read file into memory\n",
    "    signal, fs_rate = librosa.core.load(filename, SAMPLE_RATE)\n",
    "    N = len(signal)\n",
    "    duration = int(SEGMENT_TIME * fs_rate)\n",
    "\n",
    "    # Split input signal into segments\n",
    "    signal = signal[: N - (N % duration)]\n",
    "    samples = np.reshape(signal, (-1, duration))\n",
    "    \n",
    "    # Process each segment to get features\n",
    "    with Pool(4) as p: # Use 4 threads to accelerate processing\n",
    "         features = list(tqdm_notebook(p.imap(extract_feature, samples), total=len(samples)))\n",
    "\n",
    "    return np.array(features).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build single dataset with size of [N, F], \n",
    "# where N is number of segments and F is number of features for each segment\n",
    "def get_files(dirname, files):\n",
    "    X = None\n",
    "    for file in files:\n",
    "        samples_features = read_process_file(dirname + file)\n",
    "        if X is None:\n",
    "            X = samples_features\n",
    "        else:\n",
    "            X = np.vstack((X, samples_features))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  records_from_pi/normal_1.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33153a9df2564f0a81e1882f813ad4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=135), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/normal_2.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c673534f2448fe8148c5cb22fc3e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/normal_3.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf33348e045a420b99988a688cd45024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=372), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/normal_4.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb13f2b9ff84e9dafff4a3156ab3593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=411), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/normal_5.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6259e1b4da4b67bdaa075030725a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=414), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/silence_1.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa10f6de0a4649ecbb49ced9663fb626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/silence_2.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d46a3c0d9a495fa08eb5529c00adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=44), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/silence_long.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde49eff8d194d749026eaa24b6709c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/silence_short.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a2681f62844adea6246f340370e9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify audio files with normal sound recording\n",
    "# Used for training, testing and validation\n",
    "normal_file_dir = 'records_from_pi/'\n",
    "normal_files = [\n",
    "    'normal_1.wav',\n",
    "    'normal_2.wav',\n",
    "    'normal_3.wav',\n",
    "    'normal_4.wav',\n",
    "    'normal_5.wav',\n",
    "    'silence_1.wav',\n",
    "    'silence_2.wav',\n",
    "    'silence_long.wav',\n",
    "    'silence_short.wav'\n",
    "]\n",
    "\n",
    "# Append label to each segment\n",
    "X_normal = get_files(normal_file_dir, normal_files)\n",
    "normal_labels = np.ones((X_normal.shape[0], 1))\n",
    "X_normal = np.hstack((X_normal, normal_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  records_from_pi/abnormal_1.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7940f54b41284a9d849e1184ea706958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=251), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file:  records_from_pi/abnormal_2.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fdeb003b1a4895a392e2186e5e7242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=260), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify audio files with abnormal sound recording\n",
    "# Used for testing and validation\n",
    "abnormal_file_dir = 'records_from_pi/'\n",
    "abnormal_files = [\n",
    "    'abnormal_1.wav',\n",
    "    'abnormal_2.wav',\n",
    "]\n",
    "\n",
    "# Append label to each segment\n",
    "X_abnormal = get_files(abnormal_file_dir, abnormal_files)\n",
    "abnormal_labels = np.zeros((X_abnormal.shape[0], 1))\n",
    "X_abnormal = np.hstack((X_abnormal, abnormal_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data shape:  (1846, 194)\n",
      "Abnormal data shape:  (511, 194)\n",
      "Train data shape:  (1109, 193)\n",
      "Train labels shape:  (1109,)\n",
      "Validation data shape:  (606, 193)\n",
      "Validation labels shape:  (606,)\n",
      "Test data shape:  (642, 193)\n",
      "Test labels shape:  (642,)\n"
     ]
    }
   ],
   "source": [
    "# Show some output about data\n",
    "print(\"Normal data shape: \", X_normal.shape)\n",
    "print(\"Abnormal data shape: \", X_abnormal.shape)\n",
    "\n",
    "# Split normal data, get training dataset\n",
    "train_mask = np.random.choice([False, True], len(X_normal), p=[0.40, 0.60])\n",
    "X_train = X_normal[train_mask]\n",
    "np.random.shuffle(X_train)\n",
    "X_other = X_normal[~train_mask]\n",
    "\n",
    "# Concatenate remaining normal data (on that's not used for training) and abnormal data\n",
    "X_other_abnormal = np.vstack((X_abnormal, X_other))\n",
    "\n",
    "# Split concatenated data for validation and test, also shuffle data\n",
    "other_abnormal_mask = np.random.choice([False, True], len(X_other_abnormal), p=[0.50, 0.50])\n",
    "X_val = X_other_abnormal[other_abnormal_mask]\n",
    "np.random.shuffle(X_val)\n",
    "X_test = X_other_abnormal[~other_abnormal_mask]\n",
    "np.random.shuffle(X_test)\n",
    "\n",
    "# Separate labels from segment features\n",
    "label_index = 193\n",
    "Y_train = X_train[:, label_index]\n",
    "X_train = X_train[:, 0:label_index]\n",
    "\n",
    "Y_val = X_val[:, label_index]\n",
    "X_val = X_val[:, 0:label_index]\n",
    "\n",
    "Y_test = X_test[:, label_index]\n",
    "X_test = X_test[:, 0:label_index]\n",
    "\n",
    "# Show some output about data\n",
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Train labels shape: \", Y_train.shape)\n",
    "print(\"Validation data shape: \", X_val.shape)\n",
    "print(\"Validation labels shape: \", Y_val.shape)\n",
    "print(\"Test data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler to data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9405940594059405\n",
      "Test accuracy:  0.9376947040498442\n"
     ]
    }
   ],
   "source": [
    "# Also assuming that resnet feature generation is done\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Build Gaussian Mixture Model and fit to training set\n",
    "gmm_clf = GaussianMixture(covariance_type='spherical', n_components=4, max_iter=int(1e7))  # Obtained via grid search\n",
    "gmm_clf.fit(X_train)\n",
    "log_probs_val = gmm_clf.score_samples(X_val)\n",
    "# Also build Isotonic Regression for predictions\n",
    "isotonic_regressor = IsotonicRegression(out_of_bounds='clip')\n",
    "isotonic_regressor.fit(log_probs_val, Y_val)  # y_val is for labels 0 - not food 1 - food (validation set)\n",
    "\n",
    "# Obtaining results on the validation set\n",
    "log_probs_val = gmm_clf.score_samples(X_val)\n",
    "val_probabilities = isotonic_regressor.predict(log_probs_val)\n",
    "val_predictions = [1 if prob >= 0.5 else 0 for prob in val_probabilities]\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "val_correct_pred = np.equal(Y_val, val_predictions)\n",
    "val_acc = np.sum(val_correct_pred) / val_correct_pred.shape[0]\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "\n",
    "# Obtaining results on the test set\n",
    "log_probs_test = gmm_clf.score_samples(X_test)\n",
    "test_probabilities = isotonic_regressor.predict(log_probs_test)\n",
    "test_predictions = [1 if prob >= 0.5 else 0 for prob in test_probabilities]\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "test_correct_pred = np.equal(Y_test, test_predictions)\n",
    "test_acc = np.sum(test_correct_pred) / test_correct_pred.shape[0]\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your models are saved, please copy them into Raspberry PI\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "save_dirname = \"saved_models/\"\n",
    "joblib.dump(ss, save_dirname + \"ss.pkl\", compress=9)\n",
    "joblib.dump(gmm_clf, save_dirname + \"gmm_clf.pkl\", compress=9)\n",
    "joblib.dump(isotonic_regressor, save_dirname + \"isotonic_regressor.pkl\", compress=9)\n",
    "\n",
    "print(\"Your models are saved, please copy them into Raspberry PI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
